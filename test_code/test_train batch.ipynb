{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd0c4c1cf351daf665722d1c3f3e43a8a3aced6245d336eb7e46cde23f9ce339f48",
   "display_name": "Python 3.7.6 64-bit ('keras': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n",
      "1 Physical GPUs, 1 Logical GPUs\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils\n",
    "import models\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "import tensorflow as tf \n",
    " \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " x_data, y_data = utils.load_dataset_sice()\n",
    "    \n",
    "data_keys = list(x_data.keys())\n",
    "\n",
    "num_data = len(x_data)\n",
    "last_index_train = int(num_data * 0.7)\n",
    "last_index_val = int(num_data * 0.9)\n",
    "\n",
    "x_train = models.split_dictionary(x_data, data_keys[:last_index_train])\n",
    "y_train = models.split_dictionary(y_data, data_keys[:last_index_train])\n",
    "\n",
    "x_val = models.split_dictionary(x_data,  data_keys[last_index_train: last_index_val])\n",
    "y_val = models.split_dictionary(y_data,  data_keys[last_index_train: last_index_val])\n",
    "\n",
    "x_test = models.split_dictionary(x_data,  data_keys[last_index_val: -1])\n",
    "y_test = models.split_dictionary(y_data,  data_keys[last_index_val: -1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "index = 10\n",
    "keys = list(x_test.keys())\n",
    "x_test_img = cv2.imread(x_test[keys[index]])     \n",
    "y_test_img = cv2.imread(y_test[keys[index]]) \n",
    "\n",
    "# resize_\n",
    "height, width = x_test_img.shape[:2]\n",
    "\n",
    "x_test_img = cv2.resize(x_test_img, dsize=(width//4, height//4), interpolation=cv2.INTER_CUBIC) \n",
    "y_test_img = cv2.resize(y_test_img, dsize=(width//4, height//4), interpolation=cv2.INTER_CUBIC) \n",
    "# epand dim\n",
    "x_test_img = np.expand_dims(x_test_img, axis=0)\n",
    "cv2.imwrite('./test_result/img.ref.bmp',y_test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"model_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         (None, None, None, 3)     0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, None, None, 64)    1792      \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, None, None, 64)    256       \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, None, None, 64)    36928     \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, None, None, 64)    256       \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, None, None, 64)    0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, None, None, 128)   73856     \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, None, None, 128)   512       \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, None, None, 128)   147584    \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, None, None, 128)   512       \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, None, None, 128)   0         \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, None, None, 256)   295168    \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, None, None, 256)   1024      \n_________________________________________________________________\nconv2d_6 (Conv2D)            (None, None, None, 256)   590080    \n_________________________________________________________________\nbatch_normalization_6 (Batch (None, None, None, 256)   1024      \n_________________________________________________________________\nmax_pooling2d_3 (MaxPooling2 (None, None, None, 256)   0         \n_________________________________________________________________\nconv2d_7 (Conv2D)            (None, None, None, 512)   1180160   \n_________________________________________________________________\nbatch_normalization_7 (Batch (None, None, None, 512)   2048      \n_________________________________________________________________\nconv2d_8 (Conv2D)            (None, None, None, 512)   2359808   \n_________________________________________________________________\nbatch_normalization_8 (Batch (None, None, None, 512)   2048      \n_________________________________________________________________\nmax_pooling2d_4 (MaxPooling2 (None, None, None, 512)   0         \n_________________________________________________________________\nconv2d_9 (Conv2D)            (None, None, None, 512)   2359808   \n_________________________________________________________________\nbatch_normalization_9 (Batch (None, None, None, 512)   2048      \n_________________________________________________________________\nconv2d_10 (Conv2D)           (None, None, None, 512)   2359808   \n_________________________________________________________________\nbatch_normalization_10 (Batc (None, None, None, 512)   2048      \n_________________________________________________________________\nup_sampling2d_1 (UpSampling2 (None, None, None, 512)   0         \n_________________________________________________________________\nconv2d_11 (Conv2D)           (None, None, None, 256)   1179904   \n_________________________________________________________________\nbatch_normalization_11 (Batc (None, None, None, 256)   1024      \n_________________________________________________________________\nconv2d_12 (Conv2D)           (None, None, None, 256)   590080    \n_________________________________________________________________\nbatch_normalization_12 (Batc (None, None, None, 256)   1024      \n_________________________________________________________________\nup_sampling2d_2 (UpSampling2 (None, None, None, 256)   0         \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, None, None, 128)   295040    \n_________________________________________________________________\nbatch_normalization_13 (Batc (None, None, None, 128)   512       \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, None, None, 128)   147584    \n_________________________________________________________________\nbatch_normalization_14 (Batc (None, None, None, 128)   512       \n_________________________________________________________________\nup_sampling2d_3 (UpSampling2 (None, None, None, 128)   0         \n_________________________________________________________________\nconv2d_15 (Conv2D)           (None, None, None, 64)    73792     \n_________________________________________________________________\nbatch_normalization_15 (Batc (None, None, None, 64)    256       \n_________________________________________________________________\nconv2d_16 (Conv2D)           (None, None, None, 64)    36928     \n_________________________________________________________________\nbatch_normalization_16 (Batc (None, None, None, 64)    256       \n_________________________________________________________________\nup_sampling2d_4 (UpSampling2 (None, None, None, 64)    0         \n_________________________________________________________________\nconv2d_17 (Conv2D)           (None, None, None, 3)     1731      \n_________________________________________________________________\nconv2d_18 (Conv2D)           (None, None, None, 3)     84        \n=================================================================\nTotal params: 11,745,495\nTrainable params: 11,737,815\nNon-trainable params: 7,680\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "ITERATIONS = 10\n",
    "BATCH_SIZE = 4\n",
    "\n",
    "train_generator = models.data_generator_from_path(x_train, y_train, batch_size=BATCH_SIZE)\n",
    "# val_generator = models.data_generator_from_path(x_val, y_val, batch_size=BATCH_SIZE)\n",
    "\n",
    "model = models.build_model(None, None, 3)\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epochs: 0, loss: 0.07, acc: 0.36\n",
      "epochs: 100, loss: 0.04, acc: 0.28\n",
      "epochs: 200, loss: 0.03, acc: 0.61\n",
      "epochs: 300, loss: 0.04, acc: 0.21\n",
      "epochs: 400, loss: 0.04, acc: 0.25\n",
      "epochs: 500, loss: 0.07, acc: 0.38\n",
      "epochs: 600, loss: 0.04, acc: 0.24\n",
      "epochs: 700, loss: 0.02, acc: 0.54\n",
      "epochs: 800, loss: 0.06, acc: 0.39\n",
      "epochs: 900, loss: 0.03, acc: 0.34\n",
      "epochs: 1000, loss: 0.06, acc: 0.51\n",
      "epochs: 1100, loss: 0.04, acc: 0.26\n",
      "epochs: 1200, loss: 0.04, acc: 0.38\n",
      "epochs: 1300, loss: 0.03, acc: 0.34\n",
      "epochs: 1400, loss: 0.03, acc: 0.41\n",
      "epochs: 1500, loss: 0.03, acc: 0.45\n",
      "epochs: 1600, loss: 0.03, acc: 0.32\n",
      "epochs: 1700, loss: 0.02, acc: 0.39\n",
      "epochs: 1800, loss: 0.04, acc: 0.62\n",
      "epochs: 1900, loss: 0.02, acc: 0.24\n",
      "epochs: 2000, loss: 0.03, acc: 0.42\n",
      "epochs: 2100, loss: 0.05, acc: 0.22\n",
      "epochs: 2200, loss: 0.03, acc: 0.56\n",
      "epochs: 2300, loss: 0.02, acc: 0.13\n",
      "epochs: 2400, loss: 0.03, acc: 0.41\n",
      "epochs: 2500, loss: 0.04, acc: 0.22\n",
      "epochs: 2600, loss: 0.02, acc: 0.48\n",
      "epochs: 2700, loss: 0.04, acc: 0.44\n",
      "epochs: 2800, loss: 0.05, acc: 0.36\n",
      "epochs: 2900, loss: 0.02, acc: 0.37\n",
      "epochs: 3000, loss: 0.02, acc: 0.34\n",
      "epochs: 3100, loss: 0.04, acc: 0.17\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "for step in range(10000):\n",
    "    x_batch, y_batch = next(train_generator)\n",
    "    loss = model.train_on_batch(x_batch, y_batch)\n",
    "\n",
    "    if step % 100 == 0:\n",
    "        model.save_weights('./weights/ae_model.{0}.h5'.format(step))\n",
    "        print('epochs: {0}, loss: {1:.2f}, acc: {2:.2f}'.format(step, loss[0], loss[1]))\n",
    "        # inference (prediction)\n",
    "        im = model.predict(x_test_img/255.0)\n",
    "        im = im.squeeze()\n",
    "        cv2.imwrite('./test_result/img.{0}.bmp'.format(step), np.uint8(im * 255))\n",
    "        \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}