{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python376jvsc74a57bd0c4c1cf351daf665722d1c3f3e43a8a3aced6245d336eb7e46cde23f9ce339f48",
   "display_name": "Python 3.7.6 64-bit ('keras': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n",
      "1 Physical GPUs, 1 Logical GPUs\n",
      "num of train data =  251\n",
      "num of val data =  251\n",
      "batch size =  10\n",
      "epochs =  100\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, None, None, 16)    448       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, None, None, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, None, None, 8)     1160      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, None, None, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, None, None, 8)     584       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, None, None, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, None, None, 8)     584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, None, None, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, None, None, 8)     584       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2 (None, None, None, 8)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, None, None, 16)    1168      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2 (None, None, None, 16)    0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, None, None, 3)     435       \n",
      "=================================================================\n",
      "Total params: 4,963\n",
      "Trainable params: 4,963\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "25/25 [==============================] - 213s 9s/step - loss: 0.0481 - acc: 0.3747 - val_loss: 0.0443 - val_acc: 0.3092\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 201s 8s/step - loss: 0.0364 - acc: 0.3921 - val_loss: 0.0342 - val_acc: 0.4447\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 198s 8s/step - loss: 0.0299 - acc: 0.4642 - val_loss: 0.0462 - val_acc: 0.4217\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 201s 8s/step - loss: 0.0267 - acc: 0.3905 - val_loss: 0.0329 - val_acc: 0.4016\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 209s 8s/step - loss: 0.0258 - acc: 0.3804 - val_loss: 0.0239 - val_acc: 0.5517\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 224s 9s/step - loss: 0.0258 - acc: 0.4203 - val_loss: 0.0309 - val_acc: 0.4079\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 214s 9s/step - loss: 0.0247 - acc: 0.3530 - val_loss: 0.0454 - val_acc: 0.3635\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 219s 9s/step - loss: 0.0240 - acc: 0.4195 - val_loss: 0.0243 - val_acc: 0.4270\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 205s 8s/step - loss: 0.0240 - acc: 0.3876 - val_loss: 0.0331 - val_acc: 0.4276\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 199s 8s/step - loss: 0.0245 - acc: 0.4169 - val_loss: 0.0286 - val_acc: 0.4484\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 197s 8s/step - loss: 0.0247 - acc: 0.4470 - val_loss: 0.0343 - val_acc: 0.4600\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 200s 8s/step - loss: 0.0244 - acc: 0.4056 - val_loss: 0.0291 - val_acc: 0.3927\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 204s 8s/step - loss: 0.0241 - acc: 0.3851 - val_loss: 0.0290 - val_acc: 0.5080\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 208s 8s/step - loss: 0.0249 - acc: 0.4247 - val_loss: 0.0350 - val_acc: 0.4072\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 196s 8s/step - loss: 0.0237 - acc: 0.4241 - val_loss: 0.0437 - val_acc: 0.4880\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 199s 8s/step - loss: 0.0265 - acc: 0.4773 - val_loss: 0.0352 - val_acc: 0.4961\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 195s 8s/step - loss: 0.0240 - acc: 0.4115 - val_loss: 0.0271 - val_acc: 0.4506\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 200s 8s/step - loss: 0.0250 - acc: 0.4034 - val_loss: 0.0249 - val_acc: 0.3681\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 195s 8s/step - loss: 0.0234 - acc: 0.3439 - val_loss: 0.0391 - val_acc: 0.4334\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 200s 8s/step - loss: 0.0238 - acc: 0.4107 - val_loss: 0.0261 - val_acc: 0.4379\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 195s 8s/step - loss: 0.0246 - acc: 0.3872 - val_loss: 0.0462 - val_acc: 0.4108\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 198s 8s/step - loss: 0.0240 - acc: 0.4243 - val_loss: 0.0395 - val_acc: 0.4739\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 202s 8s/step - loss: 0.0234 - acc: 0.4460 - val_loss: 0.0294 - val_acc: 0.4445\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 198s 8s/step - loss: 0.0237 - acc: 0.4345 - val_loss: 0.0301 - val_acc: 0.4622\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 197s 8s/step - loss: 0.0237 - acc: 0.4256 - val_loss: 0.0482 - val_acc: 0.4055\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 198s 8s/step - loss: 0.0257 - acc: 0.4204 - val_loss: 0.0184 - val_acc: 0.4309\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 195s 8s/step - loss: 0.0229 - acc: 0.4535 - val_loss: 0.0320 - val_acc: 0.4629\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 198s 8s/step - loss: 0.0237 - acc: 0.4299 - val_loss: 0.0209 - val_acc: 0.4603\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 200s 8s/step - loss: 0.0226 - acc: 0.4429 - val_loss: 0.0405 - val_acc: 0.5279\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 203s 8s/step - loss: 0.0226 - acc: 0.4606 - val_loss: 0.0243 - val_acc: 0.4888\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 201s 8s/step - loss: 0.0230 - acc: 0.4841 - val_loss: 0.0215 - val_acc: 0.4287\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 209s 8s/step - loss: 0.0233 - acc: 0.4831 - val_loss: 0.0276 - val_acc: 0.5227\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 205s 8s/step - loss: 0.0229 - acc: 0.4826 - val_loss: 0.0377 - val_acc: 0.5457\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 207s 8s/step - loss: 0.0233 - acc: 0.4557 - val_loss: 0.0430 - val_acc: 0.5306\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 212s 8s/step - loss: 0.0226 - acc: 0.4769 - val_loss: 0.0319 - val_acc: 0.5236\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 204s 8s/step - loss: 0.0218 - acc: 0.4651 - val_loss: 0.0266 - val_acc: 0.5132\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 208s 8s/step - loss: 0.0222 - acc: 0.4637 - val_loss: 0.0388 - val_acc: 0.5293\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 201s 8s/step - loss: 0.0224 - acc: 0.4212 - val_loss: 0.0314 - val_acc: 0.5958\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 201s 8s/step - loss: 0.0221 - acc: 0.4945 - val_loss: 0.0199 - val_acc: 0.5711\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 200s 8s/step - loss: 0.0233 - acc: 0.5461 - val_loss: 0.0376 - val_acc: 0.6220\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 200s 8s/step - loss: 0.0217 - acc: 0.5133 - val_loss: 0.0296 - val_acc: 0.6208\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 202s 8s/step - loss: 0.0208 - acc: 0.5672 - val_loss: 0.0323 - val_acc: 0.5659\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 207s 8s/step - loss: 0.0215 - acc: 0.5506 - val_loss: 0.0215 - val_acc: 0.5836\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 203s 8s/step - loss: 0.0213 - acc: 0.5963 - val_loss: 0.0272 - val_acc: 0.7074\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 205s 8s/step - loss: 0.0202 - acc: 0.5902 - val_loss: 0.0305 - val_acc: 0.6385\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 200s 8s/step - loss: 0.0206 - acc: 0.5807 - val_loss: 0.0311 - val_acc: 0.6489\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 199s 8s/step - loss: 0.0199 - acc: 0.6062 - val_loss: 0.0619 - val_acc: 0.6275\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 208s 8s/step - loss: 0.0195 - acc: 0.6080 - val_loss: 0.0167 - val_acc: 0.6741\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 208s 8s/step - loss: 0.0197 - acc: 0.6269 - val_loss: 0.0249 - val_acc: 0.7235\n",
      "Epoch 50/100\n",
      "25/25 [==============================] - 202s 8s/step - loss: 0.0194 - acc: 0.6574 - val_loss: 0.0163 - val_acc: 0.6785\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 197s 8s/step - loss: 0.0202 - acc: 0.6318 - val_loss: 0.0265 - val_acc: 0.6351\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 210s 8s/step - loss: 0.0203 - acc: 0.5942 - val_loss: 0.0258 - val_acc: 0.5785\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 207s 8s/step - loss: 0.0199 - acc: 0.6026 - val_loss: 0.0243 - val_acc: 0.6995\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 212s 8s/step - loss: 0.0185 - acc: 0.6480 - val_loss: 0.0248 - val_acc: 0.6741\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 203s 8s/step - loss: 0.0196 - acc: 0.6104 - val_loss: 0.0301 - val_acc: 0.6975\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 195s 8s/step - loss: 0.0190 - acc: 0.6202 - val_loss: 0.0183 - val_acc: 0.6560\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 197s 8s/step - loss: 0.0198 - acc: 0.6210 - val_loss: 0.0369 - val_acc: 0.7337\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 198s 8s/step - loss: 0.0198 - acc: 0.6410 - val_loss: 0.0199 - val_acc: 0.7147\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 200s 8s/step - loss: 0.0186 - acc: 0.6176 - val_loss: 0.0345 - val_acc: 0.6476\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 197s 8s/step - loss: 0.0192 - acc: 0.6014 - val_loss: 0.0304 - val_acc: 0.7024\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 203s 8s/step - loss: 0.0183 - acc: 0.6494 - val_loss: 0.0229 - val_acc: 0.6947\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 199s 8s/step - loss: 0.0201 - acc: 0.6656 - val_loss: 0.0355 - val_acc: 0.6343\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 197s 8s/step - loss: 0.0201 - acc: 0.6328 - val_loss: 0.0331 - val_acc: 0.6520\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 191s 8s/step - loss: 0.0201 - acc: 0.6227 - val_loss: 0.0231 - val_acc: 0.6910\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 197s 8s/step - loss: 0.0210 - acc: 0.6255 - val_loss: 0.0189 - val_acc: 0.6693\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 200s 8s/step - loss: 0.0190 - acc: 0.6339 - val_loss: 0.0124 - val_acc: 0.6817\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 198s 8s/step - loss: 0.0198 - acc: 0.6065 - val_loss: 0.0350 - val_acc: 0.6374\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 199s 8s/step - loss: 0.0198 - acc: 0.6000 - val_loss: 0.0148 - val_acc: 0.6578\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 198s 8s/step - loss: 0.0189 - acc: 0.6176 - val_loss: 0.0270 - val_acc: 0.7319\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 194s 8s/step - loss: 0.0192 - acc: 0.6382 - val_loss: 0.0245 - val_acc: 0.5812\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 195s 8s/step - loss: 0.0191 - acc: 0.6304 - val_loss: 0.0237 - val_acc: 0.6072\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 200s 8s/step - loss: 0.0196 - acc: 0.6308 - val_loss: 0.0302 - val_acc: 0.6471\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 200s 8s/step - loss: 0.0177 - acc: 0.6315 - val_loss: 0.0197 - val_acc: 0.6499\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 199s 8s/step - loss: 0.0195 - acc: 0.6212 - val_loss: 0.0271 - val_acc: 0.7489\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 200s 8s/step - loss: 0.0207 - acc: 0.5889 - val_loss: 0.0234 - val_acc: 0.7312\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 199s 8s/step - loss: 0.0192 - acc: 0.6508 - val_loss: 0.0203 - val_acc: 0.6496\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 204s 8s/step - loss: 0.0211 - acc: 0.6058 - val_loss: 0.0271 - val_acc: 0.6149\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 198s 8s/step - loss: 0.0179 - acc: 0.6644 - val_loss: 0.0447 - val_acc: 0.6886\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 196s 8s/step - loss: 0.0194 - acc: 0.6209 - val_loss: 0.0274 - val_acc: 0.6202\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 195s 8s/step - loss: 0.0185 - acc: 0.6269 - val_loss: 0.0152 - val_acc: 0.6992\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 196s 8s/step - loss: 0.0192 - acc: 0.6470 - val_loss: 0.0230 - val_acc: 0.7256\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 196s 8s/step - loss: 0.0198 - acc: 0.6428 - val_loss: 0.0248 - val_acc: 0.7144\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 202s 8s/step - loss: 0.0196 - acc: 0.6205 - val_loss: 0.0178 - val_acc: 0.7035\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 197s 8s/step - loss: 0.0202 - acc: 0.6096 - val_loss: 0.0237 - val_acc: 0.5903\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 195s 8s/step - loss: 0.0191 - acc: 0.6165 - val_loss: 0.0281 - val_acc: 0.6633\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 197s 8s/step - loss: 0.0167 - acc: 0.6103 - val_loss: 0.0253 - val_acc: 0.6216\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 193s 8s/step - loss: 0.0187 - acc: 0.6214 - val_loss: 0.0235 - val_acc: 0.6554\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 188s 8s/step - loss: 0.0186 - acc: 0.6049 - val_loss: 0.0219 - val_acc: 0.7158\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 187s 7s/step - loss: 0.0198 - acc: 0.6279 - val_loss: 0.0271 - val_acc: 0.6403\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 187s 7s/step - loss: 0.0176 - acc: 0.6265 - val_loss: 0.0187 - val_acc: 0.5926\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 187s 7s/step - loss: 0.0181 - acc: 0.6077 - val_loss: 0.0171 - val_acc: 0.7066\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 189s 8s/step - loss: 0.0197 - acc: 0.6432 - val_loss: 0.0175 - val_acc: 0.6846\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 200s 8s/step - loss: 0.0203 - acc: 0.6258 - val_loss: 0.0406 - val_acc: 0.6096\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 206s 8s/step - loss: 0.0205 - acc: 0.6244 - val_loss: 0.0286 - val_acc: 0.6984\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 204s 8s/step - loss: 0.0188 - acc: 0.6318 - val_loss: 0.0348 - val_acc: 0.6753\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 200s 8s/step - loss: 0.0184 - acc: 0.6210 - val_loss: 0.0259 - val_acc: 0.5977\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 202s 8s/step - loss: 0.0187 - acc: 0.5986 - val_loss: 0.0235 - val_acc: 0.6767\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 201s 8s/step - loss: 0.0189 - acc: 0.6420 - val_loss: 0.0432 - val_acc: 0.7173\n",
      "Epoch 99/100\n",
      "25/25 [==============================] - 204s 8s/step - loss: 0.0181 - acc: 0.6661 - val_loss: 0.0327 - val_acc: 0.6558\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 207s 8s/step - loss: 0.0187 - acc: 0.6237 - val_loss: 0.0241 - val_acc: 0.6445\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "import utils\n",
    "import model\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "import tensorflow as tf \n",
    " \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)\n",
    "\n",
    "model, x_test, y_test = model.train(epochs=100, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ResourceExhaustedError",
     "evalue": " OOM when allocating tensor with shape[1,16,2592,3872] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node conv2d_1/convolution (defined at C:\\Users\\IT2-329\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3009) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_18431]\n\nFunction call stack:\nkeras_scratch_graph\n",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-bac658cf2a52>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my_test_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mx_text_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_text_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_text_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mresult_rgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mx_test_img_rgb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_text_img\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1460\u001b[0m                                             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1461\u001b[0m                                             \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1462\u001b[1;33m                                             callbacks=callbacks)\n\u001b[0m\u001b[0;32m   1463\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mpredict_loop\u001b[1;34m(model, f, ins, batch_size, verbose, steps, callbacks)\u001b[0m\n\u001b[0;32m    322\u001b[0m             \u001b[0mbatch_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'batch'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'size'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'predict'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'begin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbatch_index\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3725\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3726\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3727\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3729\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1549\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1550\u001b[0m     \"\"\"\n\u001b[1;32m-> 1551\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1552\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1553\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1589\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1590\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1591\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1592\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\keras\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[1,16,2592,3872] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[node conv2d_1/convolution (defined at C:\\Users\\IT2-329\\Anaconda3\\envs\\keras\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3009) ]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_keras_scratch_graph_18431]\n\nFunction call stack:\nkeras_scratch_graph\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "index = 0 \n",
    "x_text_img = cv2.imread(x_test[index]) / 255.0    \n",
    "y_test_img = cv2.imread(y_test[index]) / 255.0\n",
    "x_text_img = np.expand_dims(x_text_img, axis=0)\n",
    "\n",
    "result = model.predict(x_text_img)\n",
    "result_rgb = result.squeeze()[:,:,::-1]\n",
    "x_test_img_rgb = x_text_img.squeeze()[:,:,::-1]\n",
    "y_test_img_rgb = y_test_img[:,:,::-1]\n",
    "\n",
    "plt.figure() \n",
    "fig, axs = plt.subplots(1, 3,figsize = (20,13))\n",
    "axs[0].imshow(x_test_img_rgb)\n",
    "axs[0].set_title('input')\n",
    "axs[1].imshow(result_rgb)\n",
    "axs[1].set_title('result')\n",
    "axs[2].imshow(y_test_img_rgb)\n",
    "axs[2].set_title('gt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "cv2.imwrite('input.bmp', np.uint8(x_test_img_rgb[:,:,::-1] * 255))\n",
    "cv2.imwrite('gt.bmp', np.uint8(y_test_img_rgb[:,:,::-1] * 255))\n",
    "cv2.imwrite('result.bmp', np.uint8(result_rgb[:,:,::-1] * 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('simple_ae_100.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}